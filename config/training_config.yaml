model:
  base_model: "meta-llama/Llama-3.2-3B-Instruct"
  model_name: "llama-3.2-3b-corporate-qa"
  
training:
  # Optimized for your dataset size and H100 GPU
  batch_size: 8                    # Increased for H100 GPU
  gradient_accumulation_steps: 2   # Effective batch size of 16
  max_seq_length: 2048            
  num_train_epochs: 3             # 3 epochs should be sufficient
  learning_rate: 2e-4             # Standard for LoRA fine-tuning
  weight_decay: 0.01
  warmup_ratio: 0.1              
  lr_scheduler_type: "cosine"
  
  # LoRA configuration optimized for 3B model
  lora:
    r: 64                         # Higher rank for 3B model
    alpha: 128                    # Alpha = 2 * r is a good rule
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", 
                     "gate_proj", "up_proj", "down_proj"]
    dropout: 0.1                 
    bias: "none"
    task_type: "CAUSAL_LM"
  
  # Optimization settings
  fp16: true
  gradient_checkpointing: true
  dataloader_num_workers: 4       # Increased for H100
  remove_unused_columns: false
  
  # Evaluation and logging
  eval_steps: 50                  
  save_steps: 100                 
  logging_steps: 10                
  eval_strategy: "steps"
  save_strategy: "steps"
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  
  # Early stopping
  early_stopping_patience: 3      
  early_stopping_threshold: 0.001 

data:
  train_split: 0.8              
  val_split: 0.15               
  test_split: 0.05             
  max_length: 2048
  prompt_template: |
    <|begin_of_text|><|start_header_id|>system<|end_header_id|>
    
    {system}<|eot_id|><|start_header_id|>user<|end_header_id|>
    
    {instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>
    
    {output}<|eot_id|>

output:
  model_dir: "./output/models"
  logs_dir: "./output/logs"
  checkpoints_dir: "./output/checkpoints"