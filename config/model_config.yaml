model:
  name: "llama-3.2-3b-corporate-qa"
  base_model: "meta-llama/Llama-3.2-3B-Instruct"
  
  # Model parameters
  max_position_embeddings: 2048
  rope_theta: 500000.0
  use_cache: true
  
  # Generation parameters
  generation:
    max_new_tokens: 512
    temperature: 0.7
    top_p: 0.9
    top_k: 50
    repetition_penalty: 1.1
    do_sample: true
    pad_token_id: 128001  # Llama 3.2 pad token
    eos_token_id: 128009  # Llama 3.2 eos token
    
tokenizer:
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
  add_eos_token: true
  add_bos_token: true
  truncation: true
  padding: true
  
quantization:
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true

# HuggingFace authentication
huggingface:
  use_auth_token: true  # Will use HF_TOKEN environment variable